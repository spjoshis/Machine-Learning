{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fb0a1f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting TA-Lib\n",
      "  Using cached TA-Lib-0.4.24.tar.gz (269 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/gopaljoshi/Documents/GitHub/Object-Detection-Python/venv/lib/python3.8/site-packages (from TA-Lib) (1.21.4)\n",
      "Building wheels for collected packages: TA-Lib\n",
      "  Building wheel for TA-Lib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for TA-Lib: filename=TA_Lib-0.4.24-cp38-cp38-macosx_10_14_x86_64.whl size=811789 sha256=89368353678b79b3ec8b7f882702e6416ee68d7fdb59910630b65502271f9d87\n",
      "  Stored in directory: /Users/gopaljoshi/Library/Caches/pip/wheels/9e/9d/2b/eb5593690a0ccd184bf19016a82e9a651477c0ef6f2ba63921\n",
      "Successfully built TA-Lib\n",
      "Installing collected packages: TA-Lib\n",
      "Successfully installed TA-Lib-0.4.24\n"
     ]
    }
   ],
   "source": [
    "!/Users/gopaljoshi/Documents/GitHub/Object-Detection-Python/venv/bin/python -m pip install TA-Lib\n",
    "#import talib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e575190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "#from keras.optimizers import sgd\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "import talib\n",
    "import traceback\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0f198",
   "metadata": {},
   "source": [
    "# Parse a data file into Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "816486e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x,y: pd.to_datetime(x+' '+y).strftime('%m/%d/%Y %H:%M')\n",
    "df = pd.read_csv('data.txt',parse_dates=[[0,1]],index_col=0,skiprows=0,date_parser=dateparse)\n",
    "df.index.rename('Time',inplace=True)\n",
    "df.columns = ['open','high','low','close','volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8049822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998-01-02 09:35:00</th>\n",
       "      <td>0.4612</td>\n",
       "      <td>0.4654</td>\n",
       "      <td>0.4569</td>\n",
       "      <td>0.4654</td>\n",
       "      <td>1164092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-02 09:40:00</th>\n",
       "      <td>0.4612</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.4612</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>868636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-02 09:45:00</th>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.4654</td>\n",
       "      <td>0.4612</td>\n",
       "      <td>0.4654</td>\n",
       "      <td>1746136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-02 09:50:00</th>\n",
       "      <td>0.4654</td>\n",
       "      <td>0.4654</td>\n",
       "      <td>0.4612</td>\n",
       "      <td>0.4612</td>\n",
       "      <td>4369773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-02 09:55:00</th>\n",
       "      <td>0.4612</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.4569</td>\n",
       "      <td>0.4612</td>\n",
       "      <td>3752273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-18 19:35:00</th>\n",
       "      <td>99.3200</td>\n",
       "      <td>99.3200</td>\n",
       "      <td>99.3000</td>\n",
       "      <td>99.3200</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-18 19:40:00</th>\n",
       "      <td>99.3200</td>\n",
       "      <td>99.3200</td>\n",
       "      <td>99.3100</td>\n",
       "      <td>99.3100</td>\n",
       "      <td>1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-18 19:45:00</th>\n",
       "      <td>99.3100</td>\n",
       "      <td>99.3200</td>\n",
       "      <td>99.2900</td>\n",
       "      <td>99.3200</td>\n",
       "      <td>3723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-18 19:50:00</th>\n",
       "      <td>99.3100</td>\n",
       "      <td>99.3200</td>\n",
       "      <td>99.3000</td>\n",
       "      <td>99.3200</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-18 19:55:00</th>\n",
       "      <td>99.3200</td>\n",
       "      <td>99.3300</td>\n",
       "      <td>99.3100</td>\n",
       "      <td>99.3300</td>\n",
       "      <td>6640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518114 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open     high      low    close   volume\n",
       "Time                                                            \n",
       "1998-01-02 09:35:00   0.4612   0.4654   0.4569   0.4654  1164092\n",
       "1998-01-02 09:40:00   0.4612   0.4633   0.4612   0.4633   868636\n",
       "1998-01-02 09:45:00   0.4633   0.4654   0.4612   0.4654  1746136\n",
       "1998-01-02 09:50:00   0.4654   0.4654   0.4612   0.4612  4369773\n",
       "1998-01-02 09:55:00   0.4612   0.4633   0.4569   0.4612  3752273\n",
       "...                      ...      ...      ...      ...      ...\n",
       "2014-08-18 19:35:00  99.3200  99.3200  99.3000  99.3200     1000\n",
       "2014-08-18 19:40:00  99.3200  99.3200  99.3100  99.3100     1340\n",
       "2014-08-18 19:45:00  99.3100  99.3200  99.2900  99.3200     3723\n",
       "2014-08-18 19:50:00  99.3100  99.3200  99.3000  99.3200     1053\n",
       "2014-08-18 19:55:00  99.3200  99.3300  99.3100  99.3300     6640\n",
       "\n",
       "[518114 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf60586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the Reinforcement Learning part of the system\n",
    "\n",
    "class ExperienceReplay(object):\n",
    "    '''This class gathers and delivers the experience'''\n",
    "    def __init__(self, max_memory=100, discount=.9):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "        self.discount = discount\n",
    "\n",
    "    def remember(self, states, game_over):\n",
    "        # memory[i] = [[state_t, action_t, reward_t, state_t+1], game_over?]\n",
    "        self.memory.append([states, game_over])\n",
    "        if len(self.memory) > self.max_memory:\n",
    "            del self.memory[0]\n",
    "\n",
    "    def get_batch(self, model, batch_size=10):\n",
    "        len_memory = len(self.memory)\n",
    "        num_actions = model.output_shape[-1]\n",
    "        env_dim = self.memory[0][0][0].shape[1]\n",
    "        inputs = np.zeros((min(len_memory, batch_size), env_dim))\n",
    "        targets = np.zeros((inputs.shape[0], num_actions))\n",
    "        for i, idx in enumerate(np.random.randint(0, len_memory, size=inputs.shape[0])):\n",
    "            state_t, action_t, reward_t, state_tp1 = self.memory[idx][0]\n",
    "            game_over = self.memory[idx][1]\n",
    "\n",
    "            inputs[i:i+1] = state_t\n",
    "            # There should be no target values for actions not taken.\n",
    "            # Thou shalt not correct actions not taken #deep\n",
    "            targets[i] = model.predict(state_t)[0]\n",
    "            Q_sa = np.max(model.predict(state_tp1)[0])\n",
    "            if game_over:  # if game_over is True\n",
    "                targets[i, action_t] = reward_t\n",
    "            else:\n",
    "                # reward_t + gamma * max_a' Q(s', a')\n",
    "                targets[i, action_t] = reward_t + self.discount * Q_sa\n",
    "        return inputs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e7e1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the \"Trading Game\"\n",
    "\n",
    "class Game(object):\n",
    "    '''This is the game. It starts, then takes an action (buy or sell) at some point and finally the reverse\n",
    "    action, at which point it is game over. This is where the reward is given. The state consists of a vector\n",
    "    with different bar sizes for OLHC. They are just concatenated. \n",
    "    lkbk: determines how many bars to use - larger lkbk - bigger state\n",
    "    '''\n",
    "    def __init__(self, df, lkbk=20, max_game_len=1000, run_mode='sequential', init_idx=None):\n",
    "        self.df = df\n",
    "        self.lkbk = lkbk\n",
    "        self.max_game_len = max_game_len\n",
    "        \n",
    "        self.is_over = False\n",
    "        self.reward = 0\n",
    "        self.run_mode =  run_mode\n",
    "        self.pnl_sum = 0\n",
    "        if run_mode == 'sequential' and init_idx == None:\n",
    "            print('------No init_idx set for \"sequential\": stopping------')\n",
    "            return\n",
    "        else:\n",
    "            self.init_idx = init_idx\n",
    "        self.reset()\n",
    "        \n",
    "    def _update_state(self, action):\n",
    "        \n",
    "        '''Here we update our state'''\n",
    "        self.curr_idx += 1\n",
    "        self.curr_time = self.df.index[self.curr_idx]\n",
    "        self.curr_price = self.df['close'][self.curr_idx]\n",
    "        self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n",
    "        self._assemble_state()\n",
    "        _k = list(map(float,str(self.curr_time.time()).split(':')[:2]))\n",
    "        self._time_of_day = (_k[0]*60 + _k[1])/(24*60) \n",
    "        self._day_of_week  = self.curr_time.weekday()/6\n",
    "        self.norm_epoch = (df.index[self.curr_idx]-df.index[0]).total_seconds()/self.t_in_secs\n",
    "        \n",
    "        '''This is where we define our policy and update our position'''\n",
    "        if action == 0:  \n",
    "            pass\n",
    "        \n",
    "        elif action == 2:\n",
    "            if self.position == -1:\n",
    "                self.is_over = True\n",
    "                self._get_reward()\n",
    "                self.trade_len = self.curr_idx - self.start_idx\n",
    "   \n",
    "            elif self.position == 0:\n",
    "                self.position = 1\n",
    "                self.entry = self.curr_price\n",
    "                self.start_idx = self.curr_idx\n",
    "            else: \n",
    "                pass\n",
    "            \n",
    "        elif action == 1:\n",
    "            if self.position == 1:\n",
    "                self.is_over = True\n",
    "                self._get_reward()\n",
    "                self.trade_len = self.curr_idx - self.start_idx\n",
    "\n",
    "            elif self.position == 0:\n",
    "                self.position = -1\n",
    "                self.entry = self.curr_price\n",
    "                self.start_idx = self.curr_idx\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "    \n",
    "    def _assemble_state(self):\n",
    "        '''Here we can add other things such as indicators and times'''\n",
    "        self._get_last_N_timebars()\n",
    "        bars = [self.last5m,self.last1h,self.last1d]\n",
    "        state = []\n",
    "        candles = {j:{k:np.array([]) for k in ['open','high','low','close']} for j in range(len(bars))}\n",
    "        for j,bar in enumerate(bars):\n",
    "            for col in ['open','high','low','close']:\n",
    "                candles[j][col] = np.asarray(bar[col])\n",
    "                state += (list(np.asarray(bar[col]))[-10:])\n",
    "\n",
    "        \n",
    "        self.state = np.array([])\n",
    "        self.state = np.append(self.state,state)\n",
    "        self.state = np.append(self.state,self.position)\n",
    "        np.append(self.state,np.sign(self.pnl_sum))\n",
    "        self.state = np.append(self.state,self._time_of_day)\n",
    "        self.state = np.append(self.state,self._day_of_week)\n",
    "        \n",
    "        for c in candles:\n",
    "            try:\n",
    "                sma1 = talib.SMA(candles[c]['close'],self.lkbk-1)[-1]\n",
    "                sma2 = talib.SMA(candles[c]['close'],self.lkbk-8)[-1]\n",
    "                self.state = np.append(self.state,(sma1-sma2)/sma2)\n",
    "                self.state = np.append(self.state,sma1)\n",
    "                self.state = np.append(self.state,talib.RSI(candles[c]['close'],self.lkbk-1)[-1])\n",
    "                self.state = np.append(self.state,talib.MOM(candles[c]['close'],self.lkbk-1)[-1])\n",
    "                #self.state = np.append(self.state,talib.MACD(candles[c]['close'],fastperiod=11, slowperiod=22, signalperiod=9)[0][0])\n",
    "                self.state = np.append(self.state,talib.BOP(candles[c]['open'],\n",
    "                                               candles[c]['high'],\n",
    "                                               candles[c]['low'],\n",
    "                                               candles[c]['close'])[-1])\n",
    "                #self.state = np.append(self.state,talib.ADXR(candles[c]['high'],\n",
    "                #                               candles[c]['low'],\n",
    "                #                               candles[c]['close'],\n",
    "                #                               self.lkbk-3)[-1]) \n",
    "                #self.state = np.append(self.state,talib.STOCH(candles[c]['high'],\n",
    "                #                               candles[c]['low'],\n",
    "                #                               candles[c]['close'],5,3,0,3,0)[-1][0])\n",
    "                self.state = np.append(self.state,talib.AROONOSC(candles[c]['high'],\n",
    "                                               candles[c]['low'],\n",
    "                                               self.lkbk-3)[-1])\n",
    "            except: print(traceback.format_exc())\n",
    "        #print('-->',self.state)\n",
    "        self.state = (np.array(self.state)-np.mean(self.state))/np.std(self.state)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    def _get_last_N_timebars(self):\n",
    "        '''The lengths of the time windows are currently hardcoded.'''\n",
    "        # TODO: find better way to calculate window lengths\n",
    "        wdw5m = 9\n",
    "        wdw1h = np.ceil(self.lkbk*15/24.)\n",
    "        wdw1d = np.ceil(self.lkbk*15)\n",
    "        \n",
    "        self.last5m = self.df[self.curr_time-timedelta(wdw5m):self.curr_time].iloc[-self.lkbk:]\n",
    "        self.last1h = self.bars1h[self.curr_time-timedelta(wdw1h):self.curr_time].iloc[-self.lkbk:]\n",
    "        self.last1d = self.bars1d[self.curr_time-timedelta(wdw1d):self.curr_time].iloc[-self.lkbk:]\n",
    "        \n",
    "        '''Making sure that window lengths are sufficient'''\n",
    "        try:\n",
    "            assert(len(self.last5m)==self.lkbk)\n",
    "            assert(len(self.last1h)==self.lkbk)\n",
    "            assert(len(self.last1d)==self.lkbk)\n",
    "        except:\n",
    "            print('****Window length too short****')\n",
    "            print(len(self.last5m),len(self.last1h),len(self.last1d))\n",
    "            if self.run_mode == 'sequential':\n",
    "                self.init_idx = self.curr_idx\n",
    "                self.reset()\n",
    "            else:\n",
    "                self.reset()\n",
    "\n",
    "\n",
    "    def _get_reward(self):\n",
    "        if self.position == 1 and self.is_over:\n",
    "            pnl = (self.curr_price - self.entry)/self.entry\n",
    "            self.reward = np.sign(pnl)#-(self.curr_idx - self.start_idx)/1000.\n",
    "        elif self.position == -1 and self.is_over:\n",
    "            pnl = (-self.curr_price + self.entry)/self.entry\n",
    "            self.reward = np.sign(pnl)#-(self.curr_idx - self.start_idx)/1000.\n",
    "        #print('entry:',self.entry,'exit:',self.curr_price,'pos:',self.position,'pnl:',pnl,self.reward)\n",
    "        return self.reward\n",
    "            \n",
    "    def observe(self):\n",
    "        return np.array([self.state])\n",
    "\n",
    "    def act(self, action):\n",
    "        self._update_state(action)\n",
    "        reward = self.reward\n",
    "        game_over = self.is_over\n",
    "        return self.observe(), reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        self.pnl = 0\n",
    "        self.entry = 0\n",
    "        self._time_of_day = 0\n",
    "        self._day_of_week = 0\n",
    "        \n",
    "        if self.run_mode == 'random':\n",
    "            self.curr_idx = np.random.randint(0,len(df)-3000)\n",
    "            \n",
    "        elif self.run_mode == 'sequential':\n",
    "            self.curr_idx = self.init_idx\n",
    "            \n",
    "        self.t_in_secs = (df.index[-1]-df.index[0]).total_seconds()\n",
    "        self.start_idx = self.curr_idx\n",
    "        self.curr_time = self.df.index[self.curr_idx]\n",
    "        self.bars1h = df['close'].resample('1H',label='right',closed='right').ohlc().dropna()\n",
    "        self.bars1d = df['close'].resample('1D',label='right',closed='right').ohlc().dropna()\n",
    "        self._get_last_N_timebars()\n",
    "        self.state = []\n",
    "        self.position = 0\n",
    "        self._update_state(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5397fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the \"Game\"\n",
    "\n",
    "def run(df,fname):\n",
    "    # parameters\n",
    "    epsilon_0 = .001\n",
    "    num_actions = 3 \n",
    "    epoch = 10\n",
    "    max_memory = 10000\n",
    "    \n",
    "    batch_size = 500\n",
    "    lkbk = 25\n",
    "    START_IDX = 3000\n",
    "\n",
    "    env = Game(df, lkbk=lkbk, max_game_len=1000,init_idx=START_IDX,run_mode='sequential')\n",
    "    hidden_size = len(env.state)*2\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_size, input_shape=(len(env.state),), activation='relu'))\n",
    "    model.add(Dense(hidden_size, activation='relu'))\n",
    "    model.add(Dense(num_actions))\n",
    "    model.compile(SGD(lr=.005), \"mse\")\n",
    "\n",
    "    # If you want to continue training from a previous model, just uncomment the line bellow\n",
    "    #model.load_weights(\"indicator_model.h5\")\n",
    "\n",
    "    # Initialize experience replay object\n",
    "    exp_replay = ExperienceReplay(max_memory=max_memory)\n",
    "\n",
    "    # Train\n",
    "    win_cnt = 0\n",
    "    loss_cnt = 0\n",
    "    wins = []\n",
    "    losses = []\n",
    "    pnls = []\n",
    "    for e in range(epoch):\n",
    "        epsilon = epsilon_0**(np.log10(e))\n",
    "        env = Game(df, lkbk=lkbk, max_game_len=1000,init_idx=env.curr_idx,run_mode='sequential')\n",
    "        loss = 0.\n",
    "        env.reset()\n",
    "        game_over = False\n",
    "        # get initial input\n",
    "        input_t = env.observe()\n",
    "\n",
    "        cnt = 0\n",
    "        while not game_over:\n",
    "            cnt += 1\n",
    "            input_tm1 = input_t\n",
    "            # get next action\n",
    "\n",
    "            if np.random.rand() <= epsilon:\n",
    "                action = np.random.randint(0, num_actions, size=1)[0]\n",
    "                if env.position == 0:\n",
    "                    if action == 2:\n",
    "                        exit_action = 1\n",
    "                    elif action == 1:\n",
    "                        exit_action = 2\n",
    "                #if env.position and action == exit_action:\n",
    "                #    print('***random exit***',env.position)\n",
    "                #elif not env.position and action:\n",
    "                #    print('***random entry***',env.position)\n",
    "                    \n",
    "            elif env.position == 0:\n",
    "                q = model.predict(input_tm1)\n",
    "                action = np.argmax(q[0])\n",
    "                if action:\n",
    "                    #print(cnt)\n",
    "                    exit_action = np.argmin(q[0][1:])+1\n",
    "                \n",
    "            elif cnt > 500:\n",
    "                #print('***Time Exit***')\n",
    "                action = exit_action\n",
    "                \n",
    "            elif env.position:\n",
    "                q = model.predict(input_tm1)\n",
    "                action = np.argmax(q[0])\n",
    "\n",
    "            # apply action, get rewards and new state\n",
    "            input_t, reward, game_over = env.act(action)\n",
    "            if reward > 0:\n",
    "                win_cnt += 1\n",
    "            elif reward < 0:\n",
    "                loss_cnt += 1\n",
    "\n",
    "            # store experience\n",
    "            if action or len(exp_replay.memory)<20 or np.random.rand() < 0.1:\n",
    "                exp_replay.remember([input_tm1, action, reward, input_t], game_over)\n",
    "\n",
    "            inputs, targets = exp_replay.get_batch(model, batch_size=batch_size)\n",
    "            env.pnl_sum = sum(pnls)\n",
    "\n",
    "            zz = model.train_on_batch(inputs, targets)\n",
    "            loss += zz\n",
    "        prt_str = (\"Epoch {:03d} | Loss {:.2f} | pos {} | len {} | pnl {:.2f}% @ {:.2f}% | eps {:,.4f} | {}\".format(e, \n",
    "                                                                                      loss, \n",
    "                                                                                      env.position, \n",
    "                                                                                      env.trade_len,\n",
    "                                                                                      sum(pnls)*100,\n",
    "                                                                                      env.pnl*100,\n",
    "                                                                                      epsilon,\n",
    "                                                                                      env.curr_time))\n",
    "        print(prt_str)\n",
    "        fid = open(fname,'a')\n",
    "        fid.write(prt_str+'\\n')\n",
    "        fid.close()\n",
    "        pnls.append(env.pnl)\n",
    "        if not e%10:\n",
    "            print('----saving weights-----')\n",
    "            model.save_weights(\"indicator_model.h5\", overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cde7fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n",
      "/Users/gopaljoshi/Documents/GitHub/Object-Detection-Python/venv/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2235922530.py:35: RuntimeWarning: divide by zero encountered in log10\n",
      "  epsilon = epsilon_0**(np.log10(e))\n",
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n",
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Loss 0.15 | pos 1 | len 3 | pnl 0.00% @ 2.45% | eps inf | 1998-02-27 10:40:00\n",
      "----saving weights-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n",
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss 0.45 | pos -1 | len 2 | pnl 2.45% @ -0.54% | eps 1.0000 | 1998-02-27 11:05:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n",
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Loss 0.69 | pos -1 | len 4 | pnl 1.91% @ -0.39% | eps 0.1250 | 1998-02-27 12:35:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n",
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Loss 0.87 | pos -1 | len 60 | pnl 1.52% @ 2.20% | eps 0.0370 | 1998-03-02 11:10:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n",
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Loss 0.17 | pos 1 | len 20 | pnl 3.72% @ -1.07% | eps 0.0156 | 1998-03-02 13:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n",
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Loss 0.13 | pos 1 | len 14 | pnl 2.64% @ -1.64% | eps 0.0080 | 1998-03-02 14:20:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n",
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Loss 0.23 | pos 1 | len 15 | pnl 1.01% @ 0.24% | eps 0.0046 | 1998-03-02 15:45:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n",
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | Loss 1.51 | pos -1 | len 161 | pnl 1.24% @ -4.55% | eps 0.0029 | 1998-03-05 09:35:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n",
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | Loss 0.17 | pos 1 | len 20 | pnl -3.30% @ 0.27% | eps 0.0020 | 1998-03-05 11:25:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n",
      "/var/folders/9l/n7bj18r50b166tr2vf17df900000gp/T/ipykernel_9753/2867505677.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.pnl = (-self.entry + self.curr_price)*self.position/self.entry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | Loss 0.04 | pos -1 | len 4 | pnl -3.03% @ 1.04% | eps 0.0014 | 1998-03-05 11:55:00\n"
     ]
    }
   ],
   "source": [
    "fname = 'output1.dat'\n",
    "fid = open(fname,'w')\n",
    "fid.close()\n",
    "run(df,fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b2e9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801388f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
